{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpretml_tools import *\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier, ExplainableBoostingRegressor, merge_ebms\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset\n",
    "### (German)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load German Credit Dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data\"\n",
    "columns = [\n",
    "    'checking_status', 'duration', 'credit_history', 'purpose', 'credit_amount',\n",
    "    'savings_account', 'employment', 'installment_rate', 'personal_status_sex',\n",
    "    'other_debtors', 'present_residence', 'property', 'age', 'other_installment_plans',\n",
    "    'housing', 'existing_credits', 'job', 'num_maintenance', 'telephone', 'foreign_worker', 'target'\n",
    "]\n",
    "\n",
    "df = pd.read_csv(url, sep=' ', names=columns, header=None)\n",
    "\n",
    "# Preprocessing\n",
    "# Create binary sex feature (Male=1, Female=0)\n",
    "df['sex'] = df['personal_status_sex'].apply(lambda x: 'male' if x in ['A91', 'A93', 'A94'] else 'female')\n",
    "\n",
    "# Convert target to binary (Good credit=1, Bad credit=0)\n",
    "df['target'] = df['target'].replace({1: 1, 2: 0})\n",
    "\n",
    "features = df.columns.tolist()\n",
    "features.remove('target')\n",
    "\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "male_model = ExplainableBoostingClassifier(feature_names=X.columns.tolist())\n",
    "male_model.fit(X_train[X_train['sex'] == 'male'], y_train[X_train['sex'] == 'male'])\n",
    "\n",
    "female_model = ExplainableBoostingClassifier(feature_names=X.columns.tolist())\n",
    "female_model.fit(X_train[X_train['sex'] == 'female'], y_train[X_train['sex'] == 'female'])\n",
    "\n",
    "normal_model = ExplainableBoostingClassifier(feature_names=X.columns.tolist())\n",
    "normal_model.fit(X_train, y_train)\n",
    "\n",
    "ff_model = CombinedEBM([male_model, female_model], [0.5, 0.5])\n",
    "combined = merge_ebms([male_model, female_model])\n",
    "\n",
    "female_model_eps = ExplainableBoostingClassifier(feature_names=X.columns.tolist())\n",
    "eps = 1e-10\n",
    "female_model_eps.fit(X_train, y_train, sample_weight=X_train['sex'].map(lambda x: eps if x == 'male' else 1 - eps))\n",
    "\n",
    "male_model_eps = ExplainableBoostingClassifier(feature_names=X.columns.tolist())\n",
    "male_model_eps.fit(X_train, y_train, sample_weight=X_train['sex'].map(lambda x: 1 - eps if x == 'male' else eps))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying with custom EBMVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8cb391376a420e913ca019666a7ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Dropdown(description='Feature:', options=(('checking_status', 0), ('duration', 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "plt.ioff()\n",
    "visualizer = InterpretmlEBMVisualizer([male_model, female_model, normal_model, ff_model, combined], [\"Male Model\", \"Female Model\", \"Normal Model\", \"50-50 Model\", \"Combined\"])\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Performance Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "foi = 'sex'\n",
    "_x = X_train\n",
    "_y = y_train\n",
    "\n",
    "male_mask = _x[foi] == 'male'\n",
    "female_mask = _x[foi] == 'female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Group 1/3: 100%|██████████| 100/100 [00:01<00:00, 83.45it/s]\n",
      "Processing Group 2/3: 100%|██████████| 10/10 [00:00<00:00, 130.15it/s]\n",
      "Processing Group 3/3: 100%|██████████| 10/10 [00:00<00:00, 62.20it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba832e442aa74b0a9eea187f4b8d41ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "plt.ioff()\n",
    "analyzer = GenericGroupPerformanceAnalyzer(\n",
    "    models_to_combine=[\n",
    "        (\"Male Model\", male_model),\n",
    "        (\"Female Model\", female_model),\n",
    "        (\"Normal Model\", normal_model),\n",
    "    ],\n",
    "    baseline_models=[\n",
    "    ],\n",
    "    X_test=_x, y_test=_y,\n",
    "    male_mask=male_mask, female_mask=female_mask,\n",
    "    feature_of_interest='sex',\n",
    "    metric='log_likelihood'\n",
    ")\n",
    "analyzer.generate_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding more trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_pairs(N, random_state=None):\n",
    "    if random_state is not None:\n",
    "        random.seed(random_state)\n",
    "    pairs = [(random.uniform(0, 1), 0) for _ in range(N)]\n",
    "    pairs = [(x, 1 - x) for x, _ in pairs]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m additional_models \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (mw, fw) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mgenerate_pairs\u001b[49m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m42\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining models\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      7\u001b[0m     new_model \u001b[38;5;241m=\u001b[39m ExplainableBoostingClassifier(feature_names\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Create sample_weights based on sex\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_pairs' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "additional_models = []\n",
    "\n",
    "for (mw, fw) in tqdm(generate_pairs(100, 42), desc=\"Training models\"):\n",
    "    new_model = ExplainableBoostingClassifier(feature_names=X.columns.tolist())\n",
    "    # Create sample_weights based on sex\n",
    "    sample_weights = X_train['sex'].map(lambda x: mw if x == 'male' else fw)\n",
    "\n",
    "    # Fit the model with sample weights\n",
    "    new_model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "\n",
    "    # Add this model to our collection with the weights used\n",
    "    additional_models.append((f\"M: {mw:.2f}, F: {fw:.2f}\", new_model))\n",
    "    \n",
    "    # Save the additional_models list to a pickle file\n",
    "    with open(\"additional_models.pkl\", \"wb\") as f:\n",
    "        pickle.dump(additional_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 models\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"pickles/german/additional_models.pkl\", \"rb\") as f:\n",
    "    additional_models = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(additional_models)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Group 1/3: 100%|██████████| 100/100 [00:01<00:00, 87.29it/s]\n",
      "Processing Group 2/3: 100%|██████████| 10/10 [00:00<00:00, 125.79it/s]\n",
      "Processing Group 3/3: 100%|██████████| 10/10 [00:00<00:00, 125.66it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4a9fd25f5044feafeb508ab76d3656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "plt.ioff()\n",
    "analyzer = GenericGroupPerformanceAnalyzer(\n",
    "    models_to_combine=[\n",
    "        (\"Male Model\", male_model_eps),\n",
    "        (\"Normal Model\", normal_model),\n",
    "        (\"Female Model\", female_model_eps),\n",
    "    ],\n",
    "    baseline_models=additional_models[5:],\n",
    "    X_test=_x, y_test=_y,\n",
    "    n_combination_main=100, n_combination_sub=10,\n",
    "    male_mask=male_mask, female_mask=female_mask,\n",
    "    feature_of_interest='sex',\n",
    "    metric='log_likelihood',\n",
    ")\n",
    "analyzer.generate_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
